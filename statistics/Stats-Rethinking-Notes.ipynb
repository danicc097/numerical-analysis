{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian models\n",
    "\n",
    "Designing a simple Bayesian model benefits from a design loop with three steps.\n",
    "(1) Data story: Motivate the model by narrating how the data might arise.\n",
    "(2) Update: Educate your model by feeding it the data.\n",
    "(3) Evaluate: All statistical models require supervision, leading to model\n",
    "revision.\n",
    "\n",
    "Let's use the global water/land proportion example:\n",
    ">Suppose you have a globe representing our planet. You will toss the globe up in the air. When you\n",
    ">catch it, you will record whether or not the surface under your right index finger is water or\n",
    ">land. Then you toss the globe up in the air again and repeat the procedure.\n",
    ">The first nine samples might look like:\n",
    ">`W L W W W L W L W`\n",
    "\n",
    "1. **Data story**\n",
    "\n",
    "This story may be descriptive, specifying associations that can be used to\n",
    "predict outcomes, given observations. \n",
    "Or it may be causal, a theory of how some events\n",
    "produce other events.\n",
    "For our globe example we can simply restate the above sampling process as a data\n",
    "story:\n",
    "  (1) The true proportion of water covering the globe is $p$.\n",
    "  (2) A single toss of the globe has a probability p of producing a water (W) observation.\n",
    "  It has a probability 1 − $p$ of producing a land (L) observation.\n",
    "  (3) Each toss of the globe is independent of the others.\n",
    "\n",
    "The data story is then translated into a formal probability model.\n",
    "\n",
    "2. **Bayesian updating**\n",
    "\n",
    "Our problem is one of using the evidence to decide among different possible proportions of water on the globe. Each possible proportion may be more or less plausible, given the evidence.\n",
    "A Bayesian model begins\n",
    "with one set of plausibilities assigned to each of these possibilities. These\n",
    "are the prior plausibilities. Then it updates them in light of the data, to produce the posterior plausibilities.\n",
    "This updating process is a kind of learning called **Bayesian updating**.\n",
    "\n",
    "In the following updating process, for simplicity we assume an initial plausibility equal for\n",
    "for every water/land proportion $p$ (top left plot - dashed line). We should stay away from\n",
    "these assumptions (known as _original ignorance_) whenever we can.\n",
    "\n",
    "![](images/2023-03-09-19-50-03.png)\n",
    "\n",
    "We notice the following:\n",
    "\n",
    "- After seeing the first toss, which is a $W$ the\n",
    "model updates the plausibilities to the solid line. The plausibility of $p = 0$ has now fallen\n",
    "to exactly zero—the equivalent of “impossible.” Why? Because we observed at least one\n",
    "speck of water on the globe, so now we know there is some water.\n",
    "Likewise, the plausibility of $p > 0.5$ has increased. This is because there is not yet any\n",
    "evidence that there is land on the globe, so the initial plausibilities are\n",
    "modified to be **consistent** with this.\n",
    "Of course, in this first sample space the highest plausibility corresponds to a globe where $p=1$, i.e.\n",
    "100% land. For all we know, the evidence tells us there is only land. But **relative plausibilities** are what matter, so differences\n",
    "between them will have a higher influence as long as there is enough evidence.\n",
    "- Every time a $W$ is seen, the peak of the plausibility curve moves to the right, towards larger values of $p$. Every time an $L$ is seen, it moves\n",
    "the other direction. \n",
    "- The maximum height of the curve increases with each sample, meaning\n",
    "that fewer values of p amass more plausibility as the amount of evidence increases. \n",
    "- Notice that every updated set of plausibilities becomes the initial plausibilities for the\n",
    "next observation. Every conclusion is the starting point for future inference. However, this\n",
    "updating process works backwards just as well as forwards.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
